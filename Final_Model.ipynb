{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29d9b726-5ba3-4ee1-bf76-978adc8705be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_234433/173065181.py\", line 16, in <module>\n",
      "    from data import DataLoader as CustomDataLoader\n",
      "  File \"/workspace/hardik/data/__init__.py\", line 1, in <module>\n",
      "    from .data_loader import DataLoader\n",
      "  File \"/workspace/hardik/data/data_loader.py\", line 28, in <module>\n",
      "    from albumentations import Compose, Normalize, Resize, ShiftScaleRotate\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py\", line 6, in <module>\n",
      "    from .augmentations import *\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/__init__.py\", line 2, in <module>\n",
      "    from .blur.transforms import *\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/blur/__init__.py\", line 2, in <module>\n",
      "    from .transforms import *\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/albumentations/augmentations/blur/transforms.py\", line 9, in <module>\n",
      "    from pydantic import Field, ValidationInfo, field_validator, model_validator\n",
      "ImportError: cannot import name 'ValidationInfo' from 'pydantic' (/opt/conda/lib/python3.10/site-packages/pydantic/__init__.cpython-310-x86_64-linux-gnu.so)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import DataLoader\n",
    "import yaml\n",
    "from data import DataLoader as CustomDataLoader\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Initialize logging\n",
    "logging.basicConfig(filename='training.log', level=logging.INFO, \n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load configuration\n",
    "config_file = \"config1.yaml\"\n",
    "with open(config_file, 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "config['data_pct'] = 100\n",
    "\n",
    "# Data loading\n",
    "data_ins = CustomDataLoader(config)\n",
    "train_loader, valid_loader, test_loader = data_ins.GetMimicDataset()\n",
    "\n",
    "# Define custom BYOL model\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class PredictionHead(nn.Module):\n",
    "    def __init__(self, in_dim, hidden_dim, out_dim):\n",
    "        super(PredictionHead, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden_dim),\n",
    "            nn.BatchNorm1d(hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, out_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class BYOL(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super(BYOL, self).__init__()\n",
    "        self.backbone = backbone\n",
    "        self.projection_head = ProjectionHead(2048, 4096, 256)\n",
    "        self.prediction_head = PredictionHead(256, 4096, 256)\n",
    "\n",
    "        self.backbone_momentum = copy.deepcopy(self.backbone)\n",
    "        self.projection_head_momentum = copy.deepcopy(self.projection_head)\n",
    "\n",
    "        for param in self.backbone_momentum.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.projection_head_momentum.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.backbone(x).flatten(start_dim=1)\n",
    "        z = self.projection_head(y)\n",
    "        p = self.prediction_head(z)\n",
    "        return p\n",
    "\n",
    "    def forward_momentum(self, x):\n",
    "        y = self.backbone_momentum(x).flatten(start_dim=1)\n",
    "        z = self.projection_head_momentum(y)\n",
    "        z = z.detach()\n",
    "        return z\n",
    "\n",
    "def negative_cosine_similarity(p, z):\n",
    "    return -F.cosine_similarity(p, z.detach(), dim=-1).mean()\n",
    "\n",
    "def vicreg_loss(x, y, sim_weight=25.0, var_weight=25.0, cov_weight=1.0):\n",
    "    repr_loss = F.mse_loss(x, y)\n",
    "\n",
    "    x = x - x.mean(dim=0)\n",
    "    y = y - y.mean(dim=0)\n",
    "    \n",
    "    std_x = torch.sqrt(x.var(dim=0) + 1e-4)\n",
    "    std_y = torch.sqrt(y.var(dim=0) + 1e-4)\n",
    "    std_loss = (torch.mean(F.relu(1 - std_x)) + torch.mean(F.relu(1 - std_y))) * var_weight\n",
    "    \n",
    "    cov_x = (x.T @ x) / (x.size(0) - 1)\n",
    "    cov_y = (y.T @ y) / (y.size(0) - 1)\n",
    "    cov_loss = (off_diagonal(cov_x).pow_(2).sum() + off_diagonal(cov_y).pow_(2).sum()) * cov_weight\n",
    "    \n",
    "    return sim_weight * repr_loss + std_loss + cov_loss\n",
    "\n",
    "def off_diagonal(x):\n",
    "    n, m = x.shape\n",
    "    assert n == m\n",
    "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
    "\n",
    "# Initialize BYOL\n",
    "resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1).to(device)\n",
    "backbone = nn.Sequential(*list(resnet.children())[:-1])\n",
    "byol_model = BYOL(backbone).to(device)\n",
    "\n",
    "# BioBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "biobert_model = AutoModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\").to(device)\n",
    "\n",
    "# Define combined model\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, image_model, text_model, image_feature_dim, text_feature_dim, hidden_dim=512, num_classes=15):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.image_model = image_model\n",
    "        self.text_model = text_model\n",
    "        self.fc_image = nn.Linear(image_feature_dim, hidden_dim)\n",
    "        self.fc_text = nn.Linear(text_feature_dim, hidden_dim)\n",
    "        self.classifier = nn.Linear(hidden_dim, num_classes)\n",
    "    \n",
    "    def forward(self, images, input_ids, attention_mask):\n",
    "        image_features = self.image_model(images)\n",
    "        text_outputs = self.text_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        text_features = text_outputs.last_hidden_state[:, 0, :]\n",
    "        \n",
    "        combined_features = F.relu(self.fc_image(image_features)) + F.relu(self.fc_text(text_features))\n",
    "        output = torch.sigmoid(self.classifier(combined_features))\n",
    "        return output\n",
    "\n",
    "# Instantiate combined model\n",
    "image_feature_dim = 256  # Adjust based on your BYOL output dimension\n",
    "text_feature_dim = 768  # BioBERT output dimension\n",
    "combined_model = CombinedModel(byol_model, biobert_model, image_feature_dim, text_feature_dim).to(device)\n",
    "\n",
    "# Training and validation setup\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "optimizer = torch.optim.Adam(combined_model.parameters(), lr=learning_rate)\n",
    "classification_criterion = nn.BCELoss()\n",
    "\n",
    "# Training loop for the combined model\n",
    "total_start_time = time.time()\n",
    "roc_auc_scores = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    combined_model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in tqdm(train_loader):\n",
    "        if len(batch) == 3:\n",
    "            images, text, labels = batch\n",
    "            input_ids = text['input_ids']\n",
    "            attention_mask = text['attention_mask']\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "        elif len(batch) == 2:\n",
    "            images, labels = batch\n",
    "            input_ids = None\n",
    "            attention_mask = None\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected batch structure: {len(batch)} elements\")\n",
    "\n",
    "        # Ensure images are of correct shape and convert to tensor\n",
    "        if isinstance(images, list):\n",
    "            images = torch.stack(images)\n",
    "        \n",
    "        images = images.squeeze()\n",
    "        if len(images.shape) == 3:\n",
    "            images = images.unsqueeze(0)\n",
    "        \n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = combined_model(images, input_ids, attention_mask)\n",
    "\n",
    "        # Calculate classification loss\n",
    "        classification_loss = classification_criterion(outputs, labels)\n",
    "\n",
    "        # Calculate BYOL losses\n",
    "        p1 = byol_model(images)\n",
    "        z1 = byol_model.forward_momentum(images)\n",
    "        loss_byol = negative_cosine_similarity(p1, z1)\n",
    "        \n",
    "        # Calculate VICReg variance losses\n",
    "        variance_I = vicreg_loss(p1, z1)\n",
    "        variance_T = vicreg_loss(text_features, text_features)\n",
    "        loss_vicreg = F.mse_loss(variance_I, variance_T)\n",
    "\n",
    "        # Combined loss\n",
    "        loss = (classification_loss + loss_byol + loss_vicreg) / 3\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    logging.info(f\"Epoch [{epoch+1}/{num_epochs}], Classification Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    combined_model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(valid_loader):\n",
    "            if len(batch) == 3:\n",
    "                images, text, labels = batch\n",
    "                input_ids = text['input_ids']\n",
    "                attention_mask = text['attention_mask']\n",
    "                input_ids = input_ids.to(device)\n",
    "                attention_mask = attention_mask.to(device)\n",
    "            elif len(batch) == 2:\n",
    "                images, labels = batch\n",
    "                input_ids = None\n",
    "                attention_mask = None\n",
    "            else:\n",
    "                raise ValueError(f\"Unexpected batch structure: {len(batch)} elements\")\n",
    "\n",
    "            # Ensure images are of correct shape and convert to tensor\n",
    "            if isinstance(images, list):\n",
    "                images = torch.stack(images)\n",
    "            \n",
    "            images = images.squeeze()\n",
    "            if len(images.shape) == 3:\n",
    "                images = images.unsqueeze(0)\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = combined_model(images, input_ids, attention_mask)\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_preds.append(outputs.cpu().numpy())\n",
    "\n",
    "    all_labels = np.concatenate(all_labels)\n",
    "    all_preds = np.concatenate(all_preds)\n",
    "    roc_auc = roc_auc_score(all_labels, all_preds, average=None)\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "\n",
    "    logging.info(f\"Epoch [{epoch+1}/{num_epochs}], Validation ROC AUC: {roc_auc}\")\n",
    "\n",
    "total_end_time = time.time()\n",
    "total_duration = total_end_time - total_start_time\n",
    "logging.info(f\"Total Training Time: {total_duration:.2f} seconds\")\n",
    "\n",
    "# Plot ROC AUC scores\n",
    "plt.figure()\n",
    "for i, scores in enumerate(np.array(roc_auc_scores).T):\n",
    "    plt.plot(scores, label=f'Class {i}')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('ROC AUC Score')\n",
    "plt.legend()\n",
    "plt.title('ROC AUC Score per Class')\n",
    "plt.savefig('roc_auc_scores.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
