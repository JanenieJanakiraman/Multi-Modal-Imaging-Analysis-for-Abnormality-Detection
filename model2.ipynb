{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4deac8cc-b922-4ffe-b6b4-2fe56c480dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "\n",
    "def extract_features(image_path):\n",
    "    img_array = np.load(image_path)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    features = model.predict(img_array)\n",
    "    return image_path, features\n",
    "\n",
    "def process_batch(batch):\n",
    "    results = {}\n",
    "    for image_path in batch:\n",
    "        image_path, features = extract_features(image_path)\n",
    "        results[image_path] = features\n",
    "    return results\n",
    "\n",
    "def chunkify(lst, n):\n",
    "    return [lst[i::n] for i in range(n)]\n",
    "\n",
    "def main():\n",
    "    input_dir = '/Users/hardikchhipa/Desktop/Data manupulations projects/heart_Echo/Dataset of ECHO/HMC-QU/per-processed_imgs_A4C'\n",
    "    global model\n",
    "    model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    model = Model(inputs=model.input, outputs=model.output)\n",
    "    \n",
    "    # Get all .npy file paths\n",
    "    file_paths = []\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.npy'):\n",
    "                file_paths.append(os.path.join(root, file))\n",
    "    \n",
    "    # Divide the file paths into chunks for each CPU core\n",
    "    num_cores = cpu_count()\n",
    "    file_chunks = chunkify(file_paths, num_cores)\n",
    "    \n",
    "    # Use multiprocessing to process batches in parallel\n",
    "    with Pool(num_cores) as pool:\n",
    "        results = pool.map(process_batch, file_chunks)\n",
    "    \n",
    "    # Combine results from all processes\n",
    "    features_dict = {}\n",
    "    for result in results:\n",
    "        features_dict.update(result)\n",
    "    \n",
    "    # Check if features_dict is populated\n",
    "    if not features_dict:\n",
    "        print(\"No features extracted. Check the preprocessing and feature extraction steps.\")\n",
    "    else:\n",
    "        print(f\"Extracted features for {len(features_dict)} images.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ff62cd-c28e-40e9-a8b9-cb2f3f7c4358",
   "metadata": {},
   "source": [
    "## With TQDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff823060-ffbe-4635-9079-2ed202d93260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_features(image_path):\n",
    "    global model\n",
    "    img_array = np.load(image_path)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_input(img_array)\n",
    "    features = model.predict(img_array)\n",
    "    return image_path, features\n",
    "\n",
    "def process_batch(batch):\n",
    "    results = {}\n",
    "    for image_path in batch:\n",
    "        image_path, features = extract_features(image_path)\n",
    "        results[image_path] = features\n",
    "    return results\n",
    "\n",
    "def chunkify(lst, n):\n",
    "    return [lst[i::n] for i in range(n)]\n",
    "\n",
    "def main():\n",
    "    input_dir = '/Users/hardikchhipa/Desktop/Data manupulations projects/heart_Echo/Dataset of ECHO/HMC-QU/per-processed_imgs_A4C'\n",
    "    global model\n",
    "    model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    model = Model(inputs=model.input, outputs=model.output)\n",
    "    \n",
    "    # Get all .npy file paths\n",
    "    file_paths = []\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.npy'):\n",
    "                file_paths.append(os.path.join(root, file))\n",
    "    \n",
    "    # Divide the file paths into chunks for each CPU core\n",
    "    num_cores = cpu_count()\n",
    "    file_chunks = chunkify(file_paths, num_cores)\n",
    "    \n",
    "    # Use multiprocessing to process batches in parallel\n",
    "    with Pool(num_cores) as pool:\n",
    "        with tqdm(total=len(file_paths)) as pbar:\n",
    "            for _ in pool.imap_unordered(process_batch, file_chunks):\n",
    "                pbar.update(len(file_chunks[0]))\n",
    "    \n",
    "    # Combine results from all processes\n",
    "    features_dict = {}\n",
    "    for result in results:\n",
    "        features_dict.update(result)\n",
    "    \n",
    "    # Check if features_dict is populated\n",
    "    if not features_dict:\n",
    "        print(\"No features extracted. Check the preprocessing and feature extraction steps.\")\n",
    "    else:\n",
    "        print(f\"Extracted features for {len(features_dict)} images.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897d29f4-4a40-4d09-b2aa-c3575c42a15b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
